{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the file for feature extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Feature_Extracting.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bill():\n",
    "    '''This function compares the features of ROI and Stored features'''\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img1 = cv2.imread(\"images/One_thousand_Dram_1.jpg\", cv2.IMREAD_GRAYSCALE) # queryiamge\n",
    "\n",
    "bill = np.read()\n",
    "\n",
    "# Features\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp_image, desc_image = sift.detectAndCompute(img1, None)\n",
    "\n",
    "\n",
    "# Feature matching\n",
    "index_params = dict(algorithm=0, trees=5)\n",
    "search_params = dict()\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # trainimage\n",
    "    kp_grayframe, desc_grayframe = sift.detectAndCompute(grayframe, None)\n",
    "    matches = flann.knnMatch(desc_image, desc_grayframe, k=2)\n",
    "    \n",
    "    \n",
    "    good_points = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            good_points.append(m)\n",
    "            \n",
    "            \n",
    "    #img3 = cv2.drawMatches(img1, kp_image, grayframe, kp_grayframe, good_points, grayframe)\n",
    "    # Homography\n",
    "    if len(good_points) > 10:\n",
    "        query_pts = np.float32([kp_image[m.queryIdx].pt for m in good_points]).reshape(-1, 1, 2)\n",
    "        train_pts = np.float32([kp_grayframe[m.trainIdx].pt for m in good_points]).reshape(-1, 1, 2)\n",
    "        \n",
    "        matrix, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0)\n",
    "        #matches_mask = mask.ravel().tolist()\n",
    "        \n",
    "        # Perspective transform\n",
    "        h, w = img1.shape\n",
    "        pts = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n",
    "        \n",
    "        dst = cv2.perspectiveTransform(pts, matrix)\n",
    "        \n",
    "        homography = cv2.polylines(frame, [np.int32(dst)], True, (255, 0, 0), 3)\n",
    "        cv2.imshow(\"Homography\", homography)\n",
    "    else:\n",
    "        cv2.imshow(\"Homography\", grayframe)\n",
    "        \n",
    "        \n",
    "    #cv2.imshow(\"Image\", img)\n",
    "    #cv2.imshow(\"grayFrame\", grayframe)\n",
    "    #cv2.imshow(\"img3\", img3)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
